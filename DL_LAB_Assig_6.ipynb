{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "eae8b3ce-8280-4ef6-9b25-e0c4346d7b72",
    "_kg_hide-input": true,
    "_uuid": "6902e9c7-2db3-4f34-8c3d-2e730d7a08ea"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported Libraries\n",
      "Reading the data\n"
     ]
    }
   ],
   "source": [
    "#Importing libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import h5py\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, Flatten, MaxPool2D, Input, Dropout, Dense\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import EarlyStopping, Callback, ModelCheckpoint\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import Adam\n",
    "import os\n",
    "from pathlib import Path\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "print('Imported Libraries')\n",
    "\n",
    "print('Reading the data')\n",
    "#Reading the data\n",
    "member = ('/kaggle/input/garbage-classification/Garbage classification/Garbage classification/')\n",
    "catagories = os.listdir(member)\n",
    "list_items = []\n",
    "for cat in catagories:\n",
    "    catagory_img = (member  + cat)\n",
    "    for _ in (glob.glob(catagory_img +'/'+'*.jpg')):\n",
    "        list_items.append([cat, _])\n",
    "    \n",
    "#Convert list into dataframe\n",
    "data = pd.DataFrame(list_items,columns = ['catagory', 'filepath'], index = None)\n",
    "data = data.sample(frac=1).reset_index(drop=True)\n",
    "data.head(5)\n",
    "data.shape\n",
    "\n",
    "\n",
    "#print('Splitting the dataset')\n",
    "train_data = data[1:2000]\n",
    "val_data = data[2001:2200]\n",
    "test_data = data[2201:2527]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing for Training set\n",
    "\n",
    "def adv_preprocessing(image):\n",
    "    #loading imageswith\n",
    "\n",
    "    preimgs = []\n",
    "    img = cv2.imread(image, cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "    #Setting dimensions to resize\n",
    "    height = 224\n",
    "    width = 224\n",
    "    \n",
    "    dim = (width, height)\n",
    "    res = cv2.resize(img, dim, interpolation = cv2.INTER_LINEAR)\n",
    "    preimgs.append(res)\n",
    "        \n",
    "#Removing noise from image - Gaussian blur\n",
    "    \n",
    "    blurred_img = cv2.GaussianBlur(res, (5,5),0)\n",
    "    preimgs.append(blurred_img)\n",
    "\n",
    "    #Segmentation \n",
    "    #------------------------------------------------------------------\n",
    "    image = res\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    ret,thresh = cv2.threshold(gray, 0,255,cv2.THRESH_BINARY+ cv2.THRESH_OTSU)\n",
    "    \n",
    "    #More noise removal\n",
    "    #------------------------------------------------------------------\n",
    "    kernal = np.ones((3,3), np.uint8)\n",
    "    opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernal, iterations=2)\n",
    "    \n",
    "    #Sure background area\n",
    "    sure_bg = cv2.dilate(opening, kernal, iterations = 3)\n",
    "    \n",
    "    #Finding foreground area\n",
    "    dist_transform = cv2.distanceTransform(opening, cv2.DIST_L2, 5)\n",
    "    ret, sure_fg = cv2.threshold(dist_transform, 0.7 * dist_transform.max(), 255, 0)\n",
    "    \n",
    "    # Finding unknown region\n",
    "    sure_fg = np.uint8(sure_fg)\n",
    "    unknown = cv2.subtract(sure_bg, sure_fg)\n",
    "    \n",
    "    #Seperating different objects with different backgrounds\n",
    "    #Markers labelling\n",
    "    ret, markers  = cv2.connectedComponents(sure_fg)\n",
    "    #Add one to all labels so that sure background is 0 not 1\n",
    "    markers = markers+1\n",
    "    \n",
    "    #Mark the unknown region with 0\n",
    "    markers[unknown == 255] = 0\n",
    "    \n",
    "    markers = cv2.watershed(res, markers)\n",
    "    res[markers == -1] = [255,0,0]\n",
    "    placeholder = np.random.rand(224,224)\n",
    "    #Displaying the markers on image\n",
    "    markers = np.dstack([markers,np.zeros((224,224)), placeholder])\n",
    "    #Adding \n",
    "    preimgs.append(res)\n",
    "    preimgs.append(markers)\n",
    "    \n",
    "    return preimgs\n",
    "\n",
    "\n",
    "#----------------------------------------------------------------------------------------------#\n",
    "#Preprocessing for Validation and test data\n",
    "\n",
    "def norm_data(data):\n",
    "    batch_data = np.zeros((len(data),224,224,3))\n",
    "    batch_labels = np.zeros((len(data),6))\n",
    "    label_enc = LabelEncoder()\n",
    "    y = label_enc.fit_transform(data['catagory']) #Converting data into labels\n",
    "    y = y.reshape(-1,1)\n",
    "    onehotenc = OneHotEncoder(handle_unknown= 'ignore')\n",
    "    batch_labels = onehotenc.fit_transform(y).toarray() #Onehot Encoding data\n",
    "    \n",
    "    #Image normalization\n",
    "    height = 224\n",
    "    width = 224\n",
    "    dim = (height, width)\n",
    "    \n",
    "    for i in range(len(data)):\n",
    "        img = cv2.imread(data.iloc[i]['filepath'])\n",
    "        res_img = cv2.resize(img, dim,interpolation = cv2.INTER_LINEAR)\n",
    "        res_img = res_img.astype(np.float32)/255\n",
    "        batch_data[i] = res_img\n",
    "\n",
    "    return batch_data, batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "41623904-5c3a-4b6a-989e-9c8ba8253535",
    "_uuid": "4ed661d6-77d6-4bde-9ac5-3c8f42fd2a29"
   },
   "outputs": [],
   "source": [
    "#Generator for training data\n",
    "\n",
    "def adv_gendata(data, batch_size):\n",
    "    labelenc = LabelEncoder()\n",
    "    n = len(data)\n",
    "    steps = n//batch_size\n",
    "    data['labels'] = labelenc.fit_transform(data['catagory'])\n",
    "    enc = OneHotEncoder(handle_unknown='ignore')\n",
    "    enc_df = pd.DataFrame(enc.fit_transform(data[['labels']]).toarray())\n",
    "\n",
    "    #Defining numpy array to contain label and image data\n",
    "    \n",
    "    batch_data = np.zeros((batch_size, 224,224,3), dtype = np.float32)\n",
    "    batch_labels = np.zeros((batch_size, 6))\n",
    "    indices = np.arange(n)\n",
    "\n",
    "    c1 = 0\n",
    "    i = 0\n",
    "    #Initialize counter\n",
    "    while True:\n",
    "        np.random.shuffle(indices)\n",
    "        next_batch = indices[(i*batch_size):(i+1)*batch_size]\n",
    "        count = 0\n",
    "        \n",
    "\n",
    "        for j, idx in enumerate(next_batch):\n",
    "            if count <= batch_size-4:\n",
    "                img_name = data.iloc[idx]['filepath']\n",
    "                aug_img = adv_preprocessing(data['filepath'].iloc[idx])\n",
    "                encoded_label = enc_df.iloc[idx]\n",
    "                batch_data[count+0] = aug_img[0]\n",
    "                batch_labels[count+0] = encoded_label\n",
    "                batch_data[count+1] = aug_img[1]\n",
    "                batch_labels[count+1] = encoded_label\n",
    "                batch_data[count+2] = aug_img[2]\n",
    "                batch_labels[count+2] = encoded_label\n",
    "                batch_data[count+3] = aug_img[3]\n",
    "                batch_labels[count+3] = encoded_label\n",
    "                count +=4\n",
    "                c1 = c1+1\n",
    "                \n",
    "            else:\n",
    "                count+=1\n",
    "\n",
    "            if count==batch_size:\n",
    "                i += 1\n",
    "                break\n",
    "\n",
    "        i+=1\n",
    "        yield batch_data, batch_labels\n",
    "    \n",
    "    if i>=steps:\n",
    "        i=0   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building the model\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Input_Image (InputLayer)     (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "ConvLayer1 (Conv2D)          (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "ConvLayer2 (Conv2D)          (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "Maxpool1 (MaxPooling2D)      (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "bn1 (BatchNormalization)     (None, 112, 112, 64)      256       \n",
      "_________________________________________________________________\n",
      "ConvLayer3 (Conv2D)          (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "ConvLayer4 (Conv2D)          (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "Maxpoo12 (MaxPooling2D)      (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "bn2 (BatchNormalization)     (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "ConvLayer5 (Conv2D)          (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "Maxpool3 (MaxPooling2D)      (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "bn3 (BatchNormalization)     (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "Flatten (Flatten)            (None, 200704)            0         \n",
      "_________________________________________________________________\n",
      "FC1 (Dense)                  (None, 256)               51380480  \n",
      "_________________________________________________________________\n",
      "Dropout1 (Dropout)           (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "FC2 (Dense)                  (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "Dropout2 (Dropout)           (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "Fc3 (Dense)                  (None, 6)                 1542      \n",
      "=================================================================\n",
      "Total params: 52,004,934\n",
      "Trainable params: 52,004,038\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Input_Image (InputLayer)     (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "ConvLayer1 (Conv2D)          (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "ConvLayer2 (Conv2D)          (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "Maxpool1 (MaxPooling2D)      (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "bn1 (BatchNormalization)     (None, 112, 112, 64)      256       \n",
      "_________________________________________________________________\n",
      "ConvLayer3 (Conv2D)          (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "ConvLayer4 (Conv2D)          (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "Maxpoo12 (MaxPooling2D)      (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "bn2 (BatchNormalization)     (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "ConvLayer5 (Conv2D)          (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "Maxpool3 (MaxPooling2D)      (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "bn3 (BatchNormalization)     (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "Flatten (Flatten)            (None, 200704)            0         \n",
      "_________________________________________________________________\n",
      "FC1 (Dense)                  (None, 256)               51380480  \n",
      "_________________________________________________________________\n",
      "Dropout1 (Dropout)           (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "FC2 (Dense)                  (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "Dropout2 (Dropout)           (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "Fc3 (Dense)                  (None, 6)                 1542      \n",
      "=================================================================\n",
      "Total params: 52,004,934\n",
      "Trainable params: 52,004,038\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:34: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"In..., outputs=Tensor(\"Fc...)`\n"
     ]
    }
   ],
   "source": [
    "print('Building the model')\n",
    "\n",
    "\n",
    "#Working on the model\n",
    "def build_model():\n",
    "    model = Sequential()\n",
    "    input_size  = Input(shape = (224,224,3), name  =  'Input_Image')\n",
    "\n",
    "    #Layer 1 - Deapth Layer 1,2\n",
    "    x = Conv2D(64,(3,3), activation = 'relu', padding = 'same', name = 'ConvLayer1' )(input_size)\n",
    "    x = Conv2D(64,(3,3), activation = 'relu', padding = 'same', name = 'ConvLayer2' )(x)\n",
    "    x = MaxPool2D((2,2), name = 'Maxpool1')(x)\n",
    "    x = BatchNormalization(name = 'bn1')(x)\n",
    "\n",
    "    #Layer 2 - Deapth layer 3,4\n",
    "    x = Conv2D(128,(3,3), activation = 'relu', padding = 'same', name = 'ConvLayer3')(x)\n",
    "    x = Conv2D(128,(3,3), activation = 'relu', padding = 'same', name = 'ConvLayer4')(x)\n",
    "    x = MaxPool2D((2,2), name = 'Maxpoo12')(x)\n",
    "    x = BatchNormalization(name = 'bn2')(x)\n",
    "#     #Layer 3 - Deapth layer 3\n",
    "    x = Conv2D(256,(3,3), activation= 'relu',padding = 'same',  name = 'ConvLayer5')(x)\n",
    "    x = MaxPool2D((2,2), name = 'Maxpool3')(x)\n",
    "    x = BatchNormalization(name = 'bn3')(x)\n",
    "\n",
    "    #Flatten the model\n",
    "\n",
    "    x = Flatten(name = 'Flatten')(x)\n",
    "    x = Dense(256, activation = 'relu', name = 'FC1')(x)\n",
    "    x = Dropout(0.7, name = 'Dropout1')(x)\n",
    "    x = Dense(256, activation = 'relu', name = 'FC2')(x)\n",
    "    x = Dropout(0.7, name = 'Dropout2')(x)\n",
    "    x = Dense(6, activation = 'softmax', name = 'Fc3')(x)\n",
    "    \n",
    "    model = Model(input = input_size , output = x)\n",
    "    return model\n",
    "\n",
    "#Building the model and summary\n",
    "\n",
    "model = build_model() \n",
    "model.summary()\n",
    "\n",
    "#Initialize the first layer with the weights of Imagenet\n",
    "\n",
    "f = h5py.File('/kaggle/input/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5', 'r')\n",
    "\n",
    "#Selecting the layers for which weights needs to be set\n",
    "w,b = f['block1_conv1']['block1_conv1_W_1:0'], f['block1_conv1']['block1_conv1_b_1:0']\n",
    "model.layers[1].set_weights = [w,b]\n",
    "\n",
    "w,b = f['block1_conv2']['block1_conv2_W_1:0'], f['block1_conv2']['block1_conv2_b_1:0']\n",
    "model.layers[2].set_weights = [w,b]\n",
    "\n",
    "f.close()\n",
    "model.summary()   \n",
    "\n",
    "\n",
    "#Compiling  the model\n",
    "from keras.optimizers import SGD\n",
    "opt = SGD(lr=0.01)\n",
    "model.compile(loss = \"categorical_crossentropy\", optimizer = opt)\n",
    "es = EarlyStopping(patience=5)\n",
    "chkpt = ModelCheckpoint(filepath= 'bestmodel',save_best_only=True, save_weights_only=True)\n",
    "model.compile(loss= 'binary_crossentropy', metrics= ['accuracy'], optimizer= opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - 747s 8s/step - loss: 2.0365 - accuracy: 0.7969 - val_loss: 1.8714 - val_accuracy: 0.7487\n",
      "Epoch 2/10\n",
      "99/99 [==============================] - 743s 8s/step - loss: 0.9206 - accuracy: 0.9219 - val_loss: 4.4187 - val_accuracy: 0.7119\n",
      "Epoch 3/10\n",
      "99/99 [==============================] - 744s 8s/step - loss: 0.8683 - accuracy: 0.9311 - val_loss: 4.4187 - val_accuracy: 0.7119\n",
      "Epoch 4/10\n",
      "99/99 [==============================] - 741s 7s/step - loss: 0.7981 - accuracy: 0.9378 - val_loss: 4.4187 - val_accuracy: 0.7119\n",
      "Epoch 5/10\n",
      "99/99 [==============================] - 741s 7s/step - loss: 0.7982 - accuracy: 0.9383 - val_loss: 3.8535 - val_accuracy: 0.7487\n",
      "Epoch 6/10\n",
      "99/99 [==============================] - 743s 8s/step - loss: 0.8400 - accuracy: 0.9369 - val_loss: 4.4187 - val_accuracy: 0.7119\n",
      "Epoch 7/10\n",
      "99/99 [==============================] - 745s 8s/step - loss: 0.8146 - accuracy: 0.9407 - val_loss: 4.4187 - val_accuracy: 0.7119\n",
      "Epoch 8/10\n",
      "99/99 [==============================] - 746s 8s/step - loss: 0.7704 - accuracy: 0.9436 - val_loss: 4.4187 - val_accuracy: 0.7119\n",
      "Epoch 9/10\n",
      "99/99 [==============================] - 744s 8s/step - loss: 0.7882 - accuracy: 0.9426 - val_loss: 4.4187 - val_accuracy: 0.7119\n",
      "Epoch 10/10\n",
      "99/99 [==============================] - 744s 8s/step - loss: 0.8022 - accuracy: 0.9412 - val_loss: 4.4187 - val_accuracy: 0.7119\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f6f6c3a3eb8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training the model\n",
    "\n",
    "batch_size = 20\n",
    "train_data_gen = adv_gendata(train_data,20)\n",
    "val_data, val_labels = norm_data(val_data)\n",
    "test_data, test_labels = norm_data(test_data)\n",
    "\n",
    "nb_train_steps = train_data.shape[0]//batch_size\n",
    "\n",
    "epochs = 10\n",
    "model.fit_generator(train_data_gen,epochs=epochs, verbose = 1, steps_per_epoch=nb_train_steps, validation_data=(val_data, val_labels))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 4.312577487500898\n",
      "Test accuracy: 0.7188138961791992\n"
     ]
    }
   ],
   "source": [
    "#Evaluating the model on test data\n",
    "\n",
    "score = model.evaluate(test_data, test_labels, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
